{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M27qF7CTrBqc"
      },
      "source": [
        "# Classifying disease using Deep Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKmFmyaGunc7"
      },
      "source": [
        "# IMPORT LIBRARIES AND DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0Cx3743urFY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers, optimizers\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, Dropout\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tjIiJdM4u1IE"
      },
      "outputs": [],
      "source": [
        "# Specify training data directory\n",
        "XRay_Directory = '../data/raw/Chest_X_Ray/train'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZFbo0iCAeNe"
      },
      "outputs": [],
      "source": [
        "# List the folders in the directory\n",
        "os.listdir(XRay_Directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0RtXNn-9uWC"
      },
      "outputs": [],
      "source": [
        "# Use image generator to generate tensor images data and normalize them\n",
        "# Use 20% of the data for cross-validation\n",
        "image_generator = ImageDataGenerator(rescale = 1./255, validation_split= 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NnGV7yqd9ufD"
      },
      "outputs": [],
      "source": [
        "# Generate batches of 40 images\n",
        "# Total number of images is 133*4 = 532 images\n",
        "# Training is 428 (80%) and validation is 104 (20%)\n",
        "# Perform shuffling and image resizing\n",
        "\n",
        "train_generator = image_generator.flow_from_directory(batch_size = 40, directory= XRay_Directory, shuffle= True, target_size=(256,256), class_mode = 'categorical', subset=\"training\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KgoOjMDTUShI"
      },
      "outputs": [],
      "source": [
        "validation_generator = image_generator.flow_from_directory(batch_size = 40, directory= XRay_Directory, shuffle= True, target_size=(256,256), class_mode = 'categorical', subset=\"validation\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8lQchBKuFjaT"
      },
      "outputs": [],
      "source": [
        "# Generate a batch of 40 images and labels\n",
        "train_images, train_labels = next(train_generator)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xxa7jZYGXzaL"
      },
      "outputs": [],
      "source": [
        "train_images.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0Qfqxb3FoFr"
      },
      "outputs": [],
      "source": [
        "train_labels.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-AFP2kTJYvmm"
      },
      "outputs": [],
      "source": [
        "train_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5U_27s8F8rr"
      },
      "outputs": [],
      "source": [
        "# labels Translator\n",
        "label_names = {0 : 'Covid-19', 1 : 'Normal' , 2: 'Viral Pneumonia', 3 : 'Bacterial Pneumonia'}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlszUhNNyrl_"
      },
      "source": [
        "# VISUALIZE DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "olZZy0KbGQrz"
      },
      "outputs": [],
      "source": [
        "# Create a grid of 36 images along with their corresponding labels\n",
        "L = 6\n",
        "W = 6\n",
        "\n",
        "fig, axes = plt.subplots(L, W, figsize = (12, 12))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for i in np.arange(0, L*W):\n",
        "    axes[i].imshow(train_images[i])\n",
        "    axes[i].set_title(label_names[np.argmax(train_labels[i])])\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.subplots_adjust(wspace = 0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0GmpAjG3GiH"
      },
      "source": [
        "# IMPORT MODEL WITH PRETRAINED WEIGHTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3af8n0yK5J4"
      },
      "outputs": [],
      "source": [
        "basemodel = ResNet50(weights = 'imagenet', include_top = False, input_tensor = Input(shape=(256,256,3)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_22VrBeYK5MQ"
      },
      "outputs": [],
      "source": [
        "basemodel.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FIPKDIgCK8G5"
      },
      "outputs": [],
      "source": [
        "#freezing the model upto the last stage - 4 and re-training stage -5\n",
        "\n",
        "for layer in basemodel.layers[:-10]:\n",
        "  layers.trainable = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPAuxlN6ZnrF"
      },
      "source": [
        "# BUILD AND TRAIN DEEP LEARNING MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfa8I1SBK82d"
      },
      "outputs": [],
      "source": [
        "headmodel = basemodel.output\n",
        "headmodel = AveragePooling2D(pool_size = (4,4))(headmodel)\n",
        "headmodel = Flatten(name= 'flatten')(headmodel)\n",
        "headmodel = Dense(256, activation = \"relu\")(headmodel)\n",
        "headmodel = Dropout(0.3)(headmodel)\n",
        "headmodel = Dense(128, activation = \"relu\")(headmodel)\n",
        "headmodel = Dropout(0.2)(headmodel)\n",
        "headmodel = Dense(4, activation = 'softmax')(headmodel)\n",
        "\n",
        "model = Model(inputs = basemodel.input, outputs = headmodel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_5nSJxDLANF"
      },
      "outputs": [],
      "source": [
        "model.compile(loss = 'categorical_crossentropy', optimizer=optimizers.RMSprop(lr = 1e-4, decay = 1e-6), metrics= [\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_QL4lTXLDv1"
      },
      "outputs": [],
      "source": [
        "# using early stopping to exit training if validation loss is not decreasing even after certain epochs (patience)\n",
        "earlystopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n",
        "\n",
        "# save the best model with lower validation loss\n",
        "checkpointer = ModelCheckpoint(filepath=\"weights.hdf5\", verbose=1, save_best_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSqp1_-sWspT"
      },
      "outputs": [],
      "source": [
        "train_generator = image_generator.flow_from_directory(batch_size = 4, directory= XRay_Directory, shuffle= True, target_size=(256,256), class_mode= 'categorical', subset=\"training\")\n",
        "val_generator = image_generator.flow_from_directory(batch_size = 4, directory= XRay_Directory, shuffle= True, target_size=(256,256), class_mode= 'categorical', subset=\"validation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VplEbBNmLF7I"
      },
      "outputs": [],
      "source": [
        "history = model.fit_generator(train_generator, steps_per_epoch= train_generator.n // 4, epochs = 10, validation_data= val_generator, validation_steps= val_generator.n // 4, callbacks=[checkpointer, earlystopping])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53qDZFRn3-S1"
      },
      "source": [
        "# EVALUATE TRAINED DEEP LEARNING MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AfQ5pPAS3CQF"
      },
      "outputs": [],
      "source": [
        "history.history.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eXiDop_l5erJ"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['loss'])\n",
        "\n",
        "plt.title('Model Loss and Accuracy Progress During Training')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Training Accuracy and Loss')\n",
        "plt.legend(['Training Accuracy', 'Training Loss'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NIKapXYTYYTD"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss During Cross-Validation')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Validation Loss')\n",
        "plt.legend(['Validation Loss'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IOt4peosZMxu"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy Progress During Cross-Validation')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Validation Accuracy')\n",
        "plt.legend(['Validation Accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6DmEMEsua_56"
      },
      "outputs": [],
      "source": [
        "test_directory = '../data/raw/Chest_X_Ray/Test'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06gdW-KJbFIo"
      },
      "outputs": [],
      "source": [
        "test_gen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "test_generator = test_gen.flow_from_directory(batch_size = 40, directory= test_directory, shuffle= True, target_size=(256,256), class_mode= 'categorical')\n",
        "\n",
        "evaluate = model.evaluate_generator(test_generator, steps = test_generator.n // 4, verbose =1)\n",
        "\n",
        "print('Accuracy Test : {}'.format(evaluate[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cOGsNy5PbpE2"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "\n",
        "prediction = []\n",
        "original = []\n",
        "image = []\n",
        "\n",
        "for i in range(len(os.listdir(test_directory))):\n",
        "  for item in os.listdir(os.path.join(test_directory,str(i))):\n",
        "    img= cv2.imread(os.path.join(test_directory,str(i),item))\n",
        "    img = cv2.resize(img,(256,256))\n",
        "    image.append(img)\n",
        "    img = img / 255\n",
        "    img = img.reshape(-1,256,256,3)\n",
        "    predict = model.predict(img)\n",
        "    predict = np.argmax(predict)\n",
        "    prediction.append(predict)\n",
        "    original.append(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EIPjNOm4ZOU3"
      },
      "outputs": [],
      "source": [
        "len(original)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HuHlUhSHdJF3"
      },
      "outputs": [],
      "source": [
        "score = accuracy_score(original,prediction)\n",
        "print(\"Test Accuracy : {}\".format(score))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HAXuRyhvdXEX"
      },
      "outputs": [],
      "source": [
        "L = 5\n",
        "W = 5\n",
        "\n",
        "fig, axes = plt.subplots(L, W, figsize = (12, 12))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for i in np.arange(0, L*W):\n",
        "    axes[i].imshow(image[i])\n",
        "    axes[i].set_title('Guess={}\\nTrue={}'.format(str(label_names[prediction[i]]), str(label_names[original[i]])))\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.subplots_adjust(wspace = 1.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MkoN6f_Yg7wT"
      },
      "outputs": [],
      "source": [
        "print(classification_report(np.asarray(original), np.asarray(prediction)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5d4zcFimg-al"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(np.asarray(original), np.asarray(prediction))\n",
        "ax = plt.subplot()\n",
        "sns.heatmap(cm, annot = True, ax = ax)\n",
        "\n",
        "ax.set_xlabel('Predicted')\n",
        "ax.set_ylabel('Original')\n",
        "ax.set_title('Confusion_matrix')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
